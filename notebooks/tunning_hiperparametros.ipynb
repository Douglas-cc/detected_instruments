{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt                \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from src.wrapped import Wrapped\n",
    "from src.analysesV02 import Analytics \n",
    "from src.train import *\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando dados para treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = Analytics()\n",
    "\n",
    "wp = Wrapped(\n",
    "    '../data/row/',\n",
    "    '../data/processed/',\n",
    "    '../data/files/'\n",
    ")\n",
    "\n",
    "# dataframe\n",
    "df = wp.load_data('df_instrumentos_features_selecionadas').drop(columns=['file_name'])\n",
    "df = df.query(\"instrumento != 'voice' & instrumento != 'synthesizer'\")\n",
    "\n",
    "# dataframes por instrumentos\n",
    "inst_corda    = [\"cello\", \"guitar\", \"violin\", \"bass\", \"banjo\", \"mandolin\", \"ukulele\"]\n",
    "inst_percusao = [\"mallet_percussion\", \"drums\", \"cymbals\"]\n",
    "inst_sopro    = [\"clarinet\", \"trombone\", \"flute\", \"trumpet\", \"saxophone\"]\n",
    "inst_aerofone = [\"accordion\", \"organ\", \"piano\"] \n",
    "\n",
    "df_inst_aerofone = df[df['instrumento'].isin(inst_aerofone)]\n",
    "df_inst_sopro    = df[df['instrumento'].isin(inst_sopro)]\n",
    "df_inst_corda    = df[df['instrumento'].isin(inst_corda)]\n",
    "df_inst_percusao = df[df['instrumento'].isin(inst_percusao)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processamento\n",
    "\n",
    "- Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "df_inst_aerofone['labels'] = le.fit_transform(df_inst_aerofone.instrumento)\n",
    "df_inst_sopro['labels']    = le.fit_transform(df_inst_sopro.instrumento)\n",
    "df_inst_corda['labels']    = le.fit_transform(df_inst_corda.instrumento)\n",
    "df_inst_percusao['labels'] = le.fit_transform(df_inst_percusao.instrumento)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analise de Anomalias"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Decission Function:\n",
    "\n",
    "**decision_function():** Este método retorna o score de decisão para cada amostra. O score de decisão é uma medida de quão provável é que uma determinada amostra seja um outlier. O valor do score de decisão depende do algoritmo específico utilizado. Para alguns algoritmos, um valor maior indica uma maior probabilidade de ser um outlier, enquanto para outros, um valor menor indica uma maior probabilidade de ser um outlier.\n",
    "\n",
    "\n",
    "#### interpretando o score para o caso do KNN\n",
    "\n",
    "decision_function() do algoritmo KNN retorna a distância média das k amostras mais próximas para cada amostra no conjunto de dados. O valor retornado pelo método decision_function() pode ser interpretado como o grau de anomalia da amostra, em que valores mais altos indicam maior grau de anomalia.\n",
    "\n",
    "A interpretação do valor do score de decisão para o KNN pode ser feita considerando os seguintes pontos:\n",
    "\n",
    "Quanto maior o valor do score de decisão, maior a distância média das k amostras mais próximas. Isso significa que a amostra está mais distante das amostras vizinhas e, portanto, é menos semelhante a elas. Em outras palavras, a amostra é mais anômala em relação ao seu entorno.\n",
    "\n",
    "Para escolher um valor de corte para classificar as amostras como outlier ou normal, é importante levar em consideração a distribuição dos valores de score de decisão. Normalmente, os valores de score de decisão seguem uma distribuição normal ou uma distribuição de cauda longa. Um valor de corte adequado pode ser escolhido com base na média e no desvio padrão da distribuição dos valores de score de decisão.\n",
    "\n",
    "O valor do score de decisão não fornece informações sobre a classe de outlier à qual a amostra pertence, apenas indica a probabilidade de ser um outlier. Portanto, é importante avaliar visualmente os resultados do modelo e analisar as amostras identificadas como outliers para determinar o tipo de anomalia presente nos dados.\n",
    "\n",
    "Em resumo, o score de decisão retornado pelo KNN indica a distância média das k amostras mais próximas e pode ser interpretado como uma medida de quão anômala a amostra é em relação ao seu entorno. Um valor de corte adequado deve ser escolhido com base na distribuição dos valores de score de decisão.\n",
    "\n",
    "\n",
    "- Decission Scores:\n",
    "\n",
    "**decision_scores()** é um dos atributos mais importantes da biblioteca PyOD. Ele é usado para retornar o score de decisão para cada amostra no conjunto de dados. O score de decisão é uma medida de quão provável é que uma determinada amostra seja um outlier, e é usado para classificar cada amostra como outlier ou normal.\n",
    "\n",
    "O valor do score de decisão depende do algoritmo específico utilizado. Para alguns algoritmos, um valor maior indica uma maior probabilidade de ser um outlier, enquanto para outros, um valor menor indica uma maior probabilidade de ser um outlier. Por exemplo, no algoritmo KNN, o score de decisão é a distância média das k amostras mais próximas, enquanto no algoritmo ABOD, o score de decisão é a média das distâncias de Mahalanobis de cada amostra em relação às outras amostras.\n",
    "\n",
    "O atributo decision_scores_ é útil porque fornece uma maneira de ajustar o nível de contaminação (isto é, a proporção de outliers esperados) para um determinado conjunto de dados. A partir do score de decisão, pode-se definir um valor de corte para classificar as amostras como outliers ou normais. O valor de corte pode ser escolhido manualmente ou usando técnicas estatísticas ou de aprendizado de máquina para determinar automaticamente o melhor valor.\n",
    "\n",
    "Em resumo, o atributo decision_scores_ é usado para retornar o score de decisão para cada amostra em um conjunto de dados. O valor do score de decisão depende do algoritmo específico utilizado e é usado para classificar cada amostra como outlier ou normal, geralmente usando um valor de corte definido pelo usuário ou por uma técnica automática.\n",
    "\n",
    "- Predict:\n",
    "\n",
    "**predict():** Este método retorna uma matriz binária indicando se cada amostra é um outlier ou não. Os outliers são marcados como 1 e as amostras normais são marcadas como 0. O valor de corte para determinar se uma amostra é um outlier ou não depende do algoritmo específico utilizado e do nível de contaminação definido.\n",
    "\n",
    "- Labels:\n",
    "\n",
    "**labels_:** Este atributo retorna uma matriz binária indicando se cada amostra é um outlier ou não, assim como o método predict(). No entanto, o atributo labels_ é definido apenas para alguns algoritmos que suportam a detecção de outliers de várias classes. Nesses casos, labels_ é uma matriz em que cada linha corresponde a uma amostra e cada coluna corresponde a uma classe. O valor da célula (i,j) indica se a amostra i pertence à classe j (0 para amostras normais e 1 para outliers)\n",
    "\n",
    "\n",
    "### Principal diferenaça entre Labels e Predict:\n",
    "\n",
    "O método predict() e o atributo labels_ são usados para identificar os outliers em um conjunto de dados. No entanto, há uma diferença importante entre eles:\n",
    "\n",
    "A principal diferença entre esses dois métodos é que o predict() é usado para detectar outliers em um problema de detecção binária de outliers (onde apenas uma classe de outliers é considerada), enquanto labels_ é usado para detectar outliers em um problema de detecção multiclasse de outliers (onde existem várias classes de outliers).\n",
    "\n",
    "Por exemplo, se estivermos trabalhando com um problema de detecção binária de outliers (por exemplo, detecção de transações fraudulentas em um conjunto de dados financeiros), o método predict() seria o mais adequado para identificar os outliers. Por outro lado, se estivermos trabalhando com um problema de detecção multiclasse de outliers (por exemplo, detecção de anomalias em um sistema de produção com várias falhas diferentes), o atributo labels_ seria mais útil para identificar cada tipo de falha separadamente.\n",
    "\n",
    "Em resumo, a principal diferença entre predict() e labels_ é que o primeiro é usado em problemas de detecção binária de outliers e o segundo é usado em problemas de detecção multiclasse de outliers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tunning de Hiperparametros"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interação 0 - Metric: euclidean, Algoritmo: auto, neighbor: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/douglas/Projetos/detected_instruments/.venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/douglas/Projetos/detected_instruments/.venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/douglas/Projetos/detected_instruments/.venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/douglas/Projetos/detected_instruments/.venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/douglas/Projetos/detected_instruments/.venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/douglas/Projetos/detected_instruments/.venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/douglas/Projetos/detected_instruments/.venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/douglas/Projetos/detected_instruments/.venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/douglas/Projetos/detected_instruments/.venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/douglas/Projetos/detected_instruments/.venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/douglas/Projetos/detected_instruments/.venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/douglas/Projetos/detected_instruments/.venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/douglas/Projetos/detected_instruments/.venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/douglas/Projetos/detected_instruments/.venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/douglas/Projetos/detected_instruments/.venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/douglas/Projetos/detected_instruments/.venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/douglas/Projetos/detected_instruments/.venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/douglas/Projetos/detected_instruments/.venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/douglas/Projetos/detected_instruments/.venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/douglas/Projetos/detected_instruments/.venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "parametros = {\n",
    "    \"criterion\": Categorical(['gini','entropy']),\n",
    "    \"max_depth\": Integer(6, 20),\n",
    "    \"min_samples_split\": Integer(2, 10),\n",
    "    \"min_samples_leaf\": Integer(2, 10),\n",
    "    \"max_features\": Categorical(['auto', 'sqrt','log2']), \n",
    "    \"bootstrap\": Categorical([True, False]),\n",
    "    \"n_estimators\": Integer(100, 500)\n",
    "}\n",
    "\n",
    "result = train_tunning_hyperparameters(\n",
    "    dataframe=df_inst_percusao, \n",
    "    model=RandomForestClassifier(), \n",
    "    parameters=parametros, \n",
    "    filename=\"resultados_parametros_percusao_random_forest\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- HistGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametros = {\n",
    "    \"min_samples_leaf\": Integer(5, 20),\n",
    "    \"max_depth\": Integer(6, 20),\n",
    "    \"loss\": Categorical(['log_loss','auto','categorical_crossentropy']), \n",
    "    \"max_bins\": Integer(100, 250)\n",
    "}\n",
    "\n",
    "\n",
    "result = train_tunning_hyperparameters(\n",
    "    dataframe=df_inst_percusao, \n",
    "    model=HistGradientBoostingClassifier(), \n",
    "    parameters=parametros, \n",
    "    filename=\"resultados_parametros_percusao_histGB\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = train_tunning_hyperparameters(\n",
    "    dataframe=df_inst_aerofone, \n",
    "    model=HistGradientBoostingClassifier(), \n",
    "    parameters=parametros, \n",
    "    filename=\"resultados_parametros_aerofone_LightGBM\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d0cd7a577fc06c35e185d01be0cfbddf373ad80e2bd1d70dc00997e153ef8afb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
